{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: LoRA Fine-tuning Using NeMo Customizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "from time import sleep, time\n",
    "from openai import OpenAI\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata associated with Datasets and Customization Jobs\n",
    "os.environ[\"NVIDIA_DATASET_NAMESPACE\"] = NMS_NAMESPACE\n",
    "os.environ[\"NVIDIA_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "## Inference env vars\n",
    "os.environ[\"NVIDIA_BASE_URL\"] = NIM_URL\n",
    "\n",
    "# Data Store env vars\n",
    "os.environ[\"NVIDIA_DATASETS_URL\"] = NEMO_URL\n",
    "\n",
    "## Customizer env vars\n",
    "os.environ[\"NVIDIA_CUSTOMIZER_URL\"] = NEMO_URL\n",
    "os.environ[\"NVIDIA_OUTPUT_MODEL_DIR\"] = CUSTOMIZED_MODEL_DIR\n",
    "\n",
    "# Evaluator env vars\n",
    "os.environ[\"NVIDIA_EVALUATOR_URL\"] = NEMO_URL\n",
    "\n",
    "# Guardrails env vars\n",
    "os.environ[\"GUARDRAILS_SERVICE_URL\"] = NEMO_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack.distribution.library_client import LlamaStackAsLibraryClient\n",
    "\n",
    "client = LlamaStackAsLibraryClient(\"nvidia\")\n",
    "client.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack.apis.common.job_types import JobStatus\n",
    "\n",
    "def wait_customization_job(job_id: str, polling_interval: int = 30, timeout: int = 3600):\n",
    "    start_time = time()\n",
    "\n",
    "    res = client.post_training.job.status(job_uuid=job_id)\n",
    "    job_status = res.status\n",
    "\n",
    "    print(f\"Waiting for Customization job {job_id} to finish.\")\n",
    "    print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "    while job_status in [JobStatus.scheduled.value, JobStatus.in_progress.value]:\n",
    "        sleep(polling_interval)\n",
    "        res = client.post_training.job.status(job_uuid=job_id)\n",
    "        job_status = res.status\n",
    "\n",
    "        print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Customization Job {job_id} took more than {timeout} seconds.\")\n",
    "        \n",
    "    return job_status\n",
    "\n",
    "# When creating a customized model, NIM asynchronously loads the model in its model registry.\n",
    "# After this, we can run inference with the new model. This helper function waits for NIM to pick up the new model.\n",
    "def wait_nim_loads_customized_model(model_id: str, polling_interval: int = 10, timeout: int = 300):\n",
    "    found = False\n",
    "    start_time = time()\n",
    "\n",
    "    print(f\"Checking if NIM has loaded customized model {model_id}.\")\n",
    "\n",
    "    while not found:\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        res = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "        if model_id in [model[\"id\"] for model in res.json()[\"data\"]]:\n",
    "            found = True\n",
    "            print(f\"Model {model_id} available after {time() - start_time} seconds.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Model {model_id} not available after {time() - start_time} seconds.\")\n",
    "\n",
    "    if not found:\n",
    "        raise RuntimeError(f\"Model {model_id} not available after {timeout} seconds.\")\n",
    "\n",
    "    assert found, f\"Could not find model {model_id} in the list of available models.\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites: Configurations, Health Checks, and Namespaces\n",
    "Before you proceed, make sure that you completed the first notebook on data preparation to obtain the assets required to follow along.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure NeMo Microservices Endpoints\n",
    "This section includes importing required libraries, configuring endpoints, and performing health checks to ensure that the NeMo Data Store, NIM, and other services are running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store, Customizer, Evaluator endpoint: {NEMO_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Path to Prepared Data\n",
    "The following code sets the paths to the prepared dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"sample_data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "test_fp = f\"{EVALUATION_DATA_ROOT}/xlam-test-single.jsonl\"\n",
    "assert os.path.exists(test_fp), f\"The test data at '{test_fp}' does not exist. Please ensure that the data was prepared successfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Organization Using Namespace\n",
    "You can use a [namespace](https://developer.nvidia.com/docs/nemo-microservices/manage-entities/namespaces/index.html) to isolate and organize the artifacts in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Namespace\n",
    "Both Data Store and Entity Store use namespaces. The following code creates namespaces for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespaces(entity_host, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
    "    res = requests.post(entity_store_url, json={\"id\": namespace})\n",
    "    assert res.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Entity Store during namespace creation: {res.status_code}\"\n",
    "    print(res)\n",
    "\n",
    "    # Create namespace in Data Store\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    res = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert res.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {res.status_code}\"\n",
    "    print(res)\n",
    "\n",
    "create_namespaces(entity_host=NEMO_URL, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Namespaces\n",
    "The following [Data Store API](https://developer.nvidia.com/docs/nemo-microservices/api/datastore.html) and [Entity Store API](https://developer.nvidia.com/docs/nemo-microservices/api/entity-store.html) list the namespace created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Namespace in Data Store\n",
    "res = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store Status Code: {res.status_code}\\nResponse JSON: {json.dumps(res.json(), indent=2)}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "res = requests.get(f\"{NEMO_URL}/v1/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Entity Store Status Code: {res.status_code}\\nResponse JSON: {json.dumps(res.json(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Upload Data to NeMo Data Store\n",
    "NeMo Data Store supports data management using the Hugging Face `HfApi` Client.\n",
    "**Note that this step does not interact with Hugging Face at all, it just uses the client library to interact with NeMo Data Store.** This is in comparison to the previous notebook, where we used the load_dataset API to download the xLAM dataset from Hugging Face's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information can be found in the [documentation](https://developer.nvidia.com/docs/nemo-microservices/manage-entities/tutorials/manage-dataset-files.html#set-up-hugging-face-client)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\" \n",
    "print(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, creating a dataset programmatically requires two steps: uploading and registration. More information can be found in documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Upload Dataset Files to NeMo Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api.upload_file(path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/xlam-test-single.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other tips:\n",
    "- Take a look at the path_in_repo argument above. If there are more than one files in the subfolders:\n",
    "    - All the .jsonl files in training/ will be merged and used for training by customizer.\n",
    "    - All the .jsonl files in validation/ will be merged and used for validation by customizer.\n",
    "- NeMo Data Store generally supports data management using the [HfApi API](https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api). For example, to delete a repo, you may use:\n",
    "    ```\n",
    "    hf_api.delete_repo(\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Register the Dataset with NeMo Entity Store\n",
    "To use a dataset for operations such as evaluations and customizations, first register the dataset to refer to it by its namespace and name afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.datasets.register(...)\n",
    "response = client.datasets.register(\n",
    "    purpose=\"post-training/messages\",\n",
    "    dataset_id=DATASET_NAME,\n",
    "    source={\n",
    "        \"type\": \"uri\",\n",
    "        \"uri\": f\"hf://datasets/{repo_id}\"\n",
    "    },\n",
    "    metadata={\n",
    "        \"format\": \"json\",\n",
    "        \"description\": \"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
    "        \"provider\": \"nvidia\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Sanity check to validate dataset\n",
    "res = requests.get(url=f\"{NEMO_URL}/v1/datasets/{NMS_NAMESPACE}/{DATASET_NAME}\")\n",
    "assert res.status_code in (200, 201), f\"Status Code {res.status_code} Failed to fetch dataset {res.text}\"\n",
    "dataset_obj = res.json()\n",
    "\n",
    "print(\"Files URL:\", dataset_obj[\"files_url\"])\n",
    "assert dataset_obj[\"files_url\"] == f\"hf://datasets/{repo_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LoRA Customization with NeMo Customizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Start the Training Job\n",
    "Start the training job with the Llama Stack Post-Training client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.post_training.supervised_fine_tune(\n",
    "    job_uuid=\"\",\n",
    "    model=BASE_MODEL,\n",
    "    training_config={\n",
    "        \"n_epochs\": 2,\n",
    "        \"data_config\": {\n",
    "            \"batch_size\": 16,\n",
    "            \"dataset_id\": DATASET_NAME # NOTE: Namespace is set by `NMS_NAMESPACE` env var\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"learning_rate\": 0.0001\n",
    "        }\n",
    "    },\n",
    "    algorithm_config={\n",
    "        \"type\": \"LoRA\",\n",
    "        \"adapter_dim\": 32,\n",
    "        \"adapter_dropout\": 0.1,\n",
    "         \"alpha\": 16,\n",
    "        # NOTE: These fields are required by `AlgorithmConfig` model, but not directly used by NVIDIA\n",
    "        \"rank\": 8,\n",
    "        \"lora_attn_modules\": [],\n",
    "        \"apply_lora_to_mlp\": True,\n",
    "        \"apply_lora_to_output\": False\n",
    "    },\n",
    "    hyperparam_search_config={},\n",
    "    logger_config={},\n",
    "    checkpoint_dir=\"\",\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = res.model_dump()\n",
    "\n",
    "# To job track status\n",
    "JOB_ID = job[\"id\"]\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = job[\"output_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips:\n",
    "- To cancel a job that you scheduled incorrectly, run the following code:\n",
    "`requests.post(f\"{NEMO_URL}/v1/customization/jobs/{JOB_ID}/cancel\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Get Job Status\n",
    "The following code polls for the job's status until completion. The training job will take approximately 45 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the job to complete\n",
    "job_status = wait_customization_job(job_id=JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** Monitor the job status. Ensure training is completed before proceeding by observing the status in the response frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Validate Availability of Custom Model\n",
    "The following NeMo Entity Store API should display the model when the training job is complete. The list below shows all models filtered by your namespace and sorted by the latest first. For more information about this API, see the [NeMo Entity Store API reference](https://developer.nvidia.com/docs/nemo-microservices/api/entity-store.html). With the following code, you can find all customized models, including the one trained in the previous cells.\n",
    "Look for the name fields in the output, which should match your `CUSTOMIZED_MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"{NEMO_URL}/v1/models\", params={\"filter[namespace]\": NMS_NAMESPACE, \"sort\" : \"-created_at\"})\n",
    "\n",
    "assert response.status_code == 200, f\"Status Code {response.status_code}: Request failed. Response: {response.text}\"\n",
    "print(\"Response JSON:\", json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips:**\n",
    "- You can also find the model with its name directly:\n",
    "    ```\n",
    "    # To specifically get the custom model, you may use the following API -\n",
    "    response = requests.get(f\"{NEMO_URL}/v1/models/{CUSTOMIZED_MODEL}\")\n",
    "  \n",
    "    assert response.status_code == 200, f\"Status Code {response.status_code}: Request failed. Response: {response.text}\"\n",
    "    print(\"Response JSON:\", json.dumps(response.json(), indent=4))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fine-tuning job succeeds, we can't immediately run inference on the customized model. In the background, NIM will load newly-created models and make them available for inference. This process typically takes < 5 minutes - here, we wait for our customized model to be picked up before attempting to run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the customized model has been picked up by NIM;\n",
    "# We allow up to 5 minutes for the LoRA adapter to be loaded\n",
    "wait_nim_loads_customized_model(model_id=CUSTOMIZED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the custom LoRA model is hosted by NVIDIA NIM\n",
    "resp = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "\n",
    "models = resp.json().get(\"data\", [])\n",
    "model_names = [model[\"id\"] for model in models]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Register Customized Model with Llama Stack\n",
    "In order to run inference on the Customized Model with Llama Stack, we need to register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack.apis.models.models import ModelType\n",
    "\n",
    "client.models.register(\n",
    "    model_id=CUSTOMIZED_MODEL,\n",
    "    model_type=ModelType.llm,\n",
    "    provider_id=\"nvidia\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sanity Test the Customized Model By Running Sample Inference\n",
    "Once the model is customized, its adapter is automatically saved in NeMo Entity Store and is ready to be picked up by NVIDIA NIM.\n",
    "You can test the model by making a Chat Completion request. First, choose one of the examples from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Get Test Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Randomly choose\n",
    "test_sample = random.choice(test_data)\n",
    "\n",
    "# Transform tools to format expected by Llama Stack client\n",
    "for i, tool in enumerate(test_sample['tools']):\n",
    "    # Extract properties we will map to the expected format\n",
    "    tool = tool.get('function', {})\n",
    "    tool_name = tool.get('name')\n",
    "    tool_description = tool.get('description')\n",
    "    tool_params = tool.get('parameters', {})\n",
    "    tool_params_properties = tool_params.get('properties', {})\n",
    "\n",
    "    # Create object of parameters for this tool\n",
    "    transformed_parameters = {}\n",
    "    for name, property in tool_params_properties.items():\n",
    "        transformed_param = {\n",
    "            'param_type': property.get('type'),\n",
    "            'description': property.get('description')\n",
    "        }\n",
    "        if 'default' in property:\n",
    "            transformed_param['default'] = property['default']\n",
    "        if 'required' in property:\n",
    "            transformed_param['required'] = property['required']\n",
    "        \n",
    "        transformed_parameters[name] = transformed_param\n",
    "\n",
    "    # Update this tool in-place using the expected format\n",
    "    test_sample['tools'][i] = {\n",
    "        'tool_name': tool_name,\n",
    "        'description': tool_description,\n",
    "        'parameters': transformed_parameters\n",
    "    }\n",
    "\n",
    "# Visualize the inputs to the LLM - user query and available tools\n",
    "test_sample['messages']\n",
    "test_sample['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Send an Inference Call to NIM\n",
    "NIM exposes an OpenAI-compatible completions API endpoint, which you can query using Llama Stack inference provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.inference.chat_completion(\n",
    "    model_id=CUSTOMIZED_MODEL,\n",
    "    messages=test_sample[\"messages\"],\n",
    "    tools=test_sample[\"tools\"],\n",
    "    tool_choice=\"auto\",\n",
    "    stream=False,\n",
    "    sampling_params={\n",
    "        \"max_tokens\": 512,\n",
    "        \"strategy\": {\n",
    "            \"type\": \"top_p\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.7,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "completion.completion_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the fine-tuning job was successful, you can get an inference result comparable to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth answer\n",
    "test_sample['tool_calls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Take Note of Your Custom Model Name\n",
    "Take note of your custom model name, as you will use it to run evaluations in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
