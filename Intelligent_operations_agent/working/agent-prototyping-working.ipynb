{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd337c60-90db-4145-b8d2-e8d69d30b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcf23d-c587-4346-a09b-55bb9d4771b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from kubernetes.client.api_client import ApiClient\n",
    "from kubernetes.client.rest import ApiException\n",
    "from kubernetes.client import CoreV1Api\n",
    "from kubernetes.config import load_incluster_config\n",
    "from llama_stack_client import Agent, LlamaStackClient\n",
    "from llama_stack_client.lib.agents.client_tool import client_tool\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client.lib.agents.react.agent import ReActAgent\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "from llama_stack_client.types import UserMessage\n",
    "from rich import print\n",
    "from termcolor import cprint\n",
    "\n",
    "load_dotenv('config.env')\n",
    "\n",
    "base_url = environ.get('LLAMA_STACK_URL')\n",
    "model_id = environ.get('LLM_MODEL_ID')\n",
    "\n",
    "client = LlamaStackClient(base_url=base_url)\n",
    "\n",
    "print(f'Connected to Llama Stack server at {base_url}')\n",
    "print('Registered models:')\n",
    "print(client.models.list())\n",
    "print(f'Using model: {model_id}')\n",
    "\n",
    "\n",
    "temperature = float(environ.get(\"TEMPERATURE\", 0.0))\n",
    "strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(environ.get(\"MAX_TOKENS\", 4096))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "print(f'sampling parameters: {sampling_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71003222-900e-4aa9-88d1-8b4bbe82a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_session(agent, session_name, user_prompts):\n",
    "    session_id = agent.create_session(session_name)\n",
    "    print(f'Created new session {session_name}')\n",
    "    print(f'Looping over user prompts: {user_prompts}')\n",
    "    for prompt in user_prompts:\n",
    "        print(\"\\n\"+\"=\"*50)\n",
    "        cprint(f\"Processing user query: {prompt}\", \"blue\")\n",
    "        print(\"=\"*50)\n",
    "        response = agent.create_turn(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            session_id=session_id,\n",
    "            stream='True'\n",
    "        )\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_namespace_errors_improved(namespace, client, model_id, sampling_params, max_infer_iters=5):\n",
    "    \"\"\"\n",
    "    Analyze pod logs and events in a given namespace for errors with improved stopping criteria.\n",
    "    \n",
    "    Args:\n",
    "        namespace (str): The namespace to analyze\n",
    "        client: LlamaStackClient instance\n",
    "        model_id (str): Model identifier to use\n",
    "        sampling_params (dict): Sampling parameters for the model\n",
    "        max_infer_iters (int): Maximum inference iterations (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results with errors found or \"No error found\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create ReAct agent with OpenShift tools\n",
    "    full_react_agent = ReActAgent(\n",
    "        client=client,\n",
    "        model=model_id,\n",
    "        tools=[\"mcp::openshift\"],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": ReActOutput.model_json_schema(),\n",
    "        },\n",
    "        sampling_params=sampling_params,\n",
    "        max_infer_iters=max_infer_iters\n",
    "    )\n",
    "    \n",
    "    # Create analysis prompt with clear stopping criteria\n",
    "    analysis_prompt = f\"\"\"You are an expert OpenShift administrator. Your task is to analyze pod logs and events in namespace '{namespace}'.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. List all pods in the namespace ONCE\n",
    "2. Check pod logs for each pod ONCE only\n",
    "3. Check events in the namespace ONCE only\n",
    "4. Analyze the pod status and identify any errors\n",
    "5. Provide a final summary with specific error details\n",
    "\n",
    "STOPPING CRITERIA - STOP AFTER:\n",
    "- Listing pods once\n",
    "- Checking logs once per pod\n",
    "- Checking events once\n",
    "- Providing final analysis\n",
    "\n",
    "DO NOT:\n",
    "- Repeat the same tool calls\n",
    "- Keep checking logs and events repeatedly\n",
    "- Continue after you have enough information\n",
    "\n",
    "Expected output format:\n",
    "- Namespace: {namespace}\n",
    "- Pod: [pod name]\n",
    "- Error Title: [error type/reason] \n",
    "- Error Description: [detailed error message]\n",
    "\n",
    "If no errors found, return: \"No error found\"\n",
    "\"\"\"\n",
    "    \n",
    "    # Create session and run analysis\n",
    "    session_id = full_react_agent.create_session(f'analysis-{namespace}')\n",
    "    print(f'Created analysis session for namespace: {namespace}')\n",
    "    \n",
    "    try:\n",
    "        # Run the analysis\n",
    "        response = full_react_agent.create_turn(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": analysis_prompt,\n",
    "                }\n",
    "            ],\n",
    "            session_id=session_id,\n",
    "            stream='True'\n",
    "        )\n",
    "        \n",
    "        # Collect the response and extract final answer\n",
    "        analysis_result = \"\"\n",
    "        final_answer = None\n",
    "        \n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "            \n",
    "            # Try to extract the final answer from the response\n",
    "            if hasattr(log, 'content'):\n",
    "                content_str = str(log.content)\n",
    "                if '\"answer\":' in content_str and '\"answer\": null' not in content_str:\n",
    "                    # Extract the answer field\n",
    "                    import re\n",
    "                    answer_match = re.search(r'\"answer\":\\s*\"([^\"]*)\"', content_str)\n",
    "                    if answer_match:\n",
    "                        final_answer = answer_match.group(1)\n",
    "        \n",
    "        # Use final answer if found, otherwise use the last content\n",
    "        if final_answer:\n",
    "            analysis_result = final_answer\n",
    "        else:\n",
    "            analysis_result = \"Analysis completed but no clear answer extracted\"\n",
    "        \n",
    "        return {\n",
    "            \"namespace\": namespace,\n",
    "            \"status\": \"completed\",\n",
    "            \"result\": analysis_result,\n",
    "            \"session_id\": session_id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"namespace\": namespace,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"session_id\": session_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the improved function with better stopping criteria\n",
    "namespace = \"oom-test\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING IMPROVED FUNCTION WITH BETTER STOPPING CRITERIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Call the improved analysis function\n",
    "result = analyze_namespace_errors_improved(\n",
    "    namespace=namespace,\n",
    "    client=client,\n",
    "    model_id=model_id,\n",
    "    sampling_params=sampling_params,\n",
    "    max_infer_iters=5  # Reduced from 10 to 5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Namespace: {result['namespace']}\")\n",
    "print(f\"Status: {result['status']}\")\n",
    "if result['status'] == 'completed':\n",
    "    print(f\"Result: {result['result']}\")\n",
    "else:\n",
    "    print(f\"Error: {result['error']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a476e-63f3-43d5-bf7a-14514a958c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def error_analysis(namespace):\n",
    "    max_infer_iters = 10\n",
    "    full_react_agent = ReActAgent(\n",
    "        client=client,\n",
    "        model=model_id,\n",
    "        tools=[\"mcp::openshift\"],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": ReActOutput.model_json_schema(),\n",
    "        },\n",
    "        sampling_params=sampling_params,\n",
    "        max_infer_iters=max_infer_iters\n",
    "    )\n",
    "\n",
    "    user_prompts = [\n",
    "        f\"\"\"You are an expert OpenShift administrator. Your task is to analyze pod logs and events, If no errors found, return \"No error found\"\n",
    "        Check namespace '{namespace}' for all errors and events. List each error with:\n",
    "    - Namespace: {namespace}\n",
    "    - Pod: [pod name]\n",
    "    - Error Title: [error type/reason]\n",
    "    - Error Description: [detailed error message]\n",
    "    \"\"\"\n",
    "    ]\n",
    "    run_session(full_react_agent, 'mcp-session', user_prompts)\n",
    "\n",
    "namespace = \"oom-test\"\n",
    "error_analysis(namespace)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
