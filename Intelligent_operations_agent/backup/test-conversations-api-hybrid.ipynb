{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Conversations API + MCP Tools Hybrid Approach\n",
        "\n",
        "This notebook uses the Conversations API for conversation flow but calls MCP tools manually for Jira operations.\n",
        "\n",
        "## Key Insight:\n",
        "**Conversations API doesn't support MCP tools directly** - it only supports built-in tools like `web_search`, `file_search`, and `function`.\n",
        "\n",
        "## Hybrid Solution:\n",
        "- Use **Conversations API** for natural conversation flow\n",
        "- Use **MCP tools directly** for Jira operations\n",
        "- Combine both approaches for the best user experience\n",
        "\n",
        "## Goal:\n",
        "- Create Jira issues using a hybrid approach\n",
        "- Maintain conversation context\n",
        "- Provide automatic tool execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from llama_stack_client import LlamaStackClient\n",
        "\n",
        "# Load configuration\n",
        "load_dotenv('config.env')\n",
        "base_url = os.environ.get('LLAMA_STACK_URL', 'http://localhost:8321')\n",
        "model_id = os.environ.get('LLM_MODEL_ID', 'r1-qwen-14b-w4a16')\n",
        "\n",
        "print(f\"üîó Connecting to: {base_url}\")\n",
        "print(f\"ü§ñ Using model: {model_id}\")\n",
        "\n",
        "# Create client\n",
        "client = LlamaStackClient(base_url=base_url)\n",
        "print(\"‚úÖ Client created\")\n",
        "\n",
        "# Check available MCP tools\n",
        "print(\"\\nüîç Checking available MCP Atlassian tools...\")\n",
        "try:\n",
        "    tools = client.tools.list(toolgroup_id=\"mcp::atlassian\")\n",
        "    print(f\"‚úÖ Found {len(tools)} Atlassian tools\")\n",
        "    \n",
        "    # Find Jira tools\n",
        "    jira_tools = [t for t in tools if 'jira' in str(t).lower()]\n",
        "    print(f\"üé´ Jira tools: {len(jira_tools)}\")\n",
        "    \n",
        "    # Show create and search tools\n",
        "    for tool in jira_tools:\n",
        "        tool_name = getattr(tool, 'name', getattr(tool, 'identifier', str(tool)))\n",
        "        if 'create' in tool_name or 'search' in tool_name:\n",
        "            print(f\"  - {tool_name}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading tools: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid Function: Conversations API + MCP Tools\n",
        "def create_jira_with_conversations(prompt, previous_response_id=None):\n",
        "    \"\"\"Use Conversations API for conversation flow and MCP tools for Jira operations\"\"\"\n",
        "    print(f\"\\nüß™ Creating Jira issue with Conversations API: {prompt}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Use Conversations API for natural conversation\n",
        "        print(\"ü§ñ Step 1: Using Conversations API for conversation flow...\")\n",
        "        \n",
        "        # First, get the AI's response about what to do\n",
        "        conversation_response = client.responses.create(\n",
        "            model=model_id,\n",
        "            input=f\"\"\"You are a Jira assistant. The user wants to: {prompt}\n",
        "            \n",
        "            Please analyze this request and provide:\n",
        "            1. A clear summary of what Jira issue needs to be created\n",
        "            2. The specific parameters needed (project_key, summary, issue_type, description, priority, labels)\n",
        "            3. A confirmation that you understand the request\n",
        "            \n",
        "            Format your response as JSON with these fields:\n",
        "            - summary: Brief description of the issue\n",
        "            - project_key: The Jira project key\n",
        "            - issue_type: Type of issue (Task, Bug, Incident, etc.)\n",
        "            - description: Detailed description\n",
        "            - priority: Priority level (Low, Medium, High, Critical)\n",
        "            - labels: List of labels to apply\n",
        "            - confirmation: Your understanding of the request\"\"\",\n",
        "            previous_response_id=previous_response_id\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ Conversations API response received!\")\n",
        "        print(f\"Response ID: {conversation_response.id}\")\n",
        "        print(f\"Response content: {conversation_response.output[0].content[0].text}\")\n",
        "        \n",
        "        # Step 2: Parse the AI's response and extract parameters\n",
        "        print(\"\\nüîß Step 2: Parsing AI response and extracting parameters...\")\n",
        "        \n",
        "        # Try to extract JSON from the response\n",
        "        try:\n",
        "            # Look for JSON in the response content\n",
        "            content = conversation_response.output[0].content[0].text\n",
        "            if '{' in content and '}' in content:\n",
        "                # Extract JSON part\n",
        "                start = content.find('{')\n",
        "                end = content.rfind('}') + 1\n",
        "                json_str = content[start:end]\n",
        "                issue_params = json.loads(json_str)\n",
        "                print(f\"‚úÖ Extracted parameters: {issue_params}\")\n",
        "            else:\n",
        "                # Fallback: create basic parameters from the prompt\n",
        "                issue_params = {\n",
        "                    \"summary\": \"Conversations API Generated Issue\",\n",
        "                    \"project_key\": \"KAN\",\n",
        "                    \"issue_type\": \"Task\",\n",
        "                    \"description\": prompt,\n",
        "                    \"priority\": \"Medium\",\n",
        "                    \"labels\": [\"conversations-api\", \"auto-generated\"]\n",
        "                }\n",
        "                print(f\"‚ö†Ô∏è  Using fallback parameters: {issue_params}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  JSON parsing failed, using fallback: {e}\")\n",
        "            issue_params = {\n",
        "                \"summary\": \"Conversations API Generated Issue\",\n",
        "                \"project_key\": \"KAN\",\n",
        "                \"issue_type\": \"Task\",\n",
        "                \"description\": prompt,\n",
        "                \"priority\": \"Medium\",\n",
        "                \"labels\": [\"conversations-api\", \"auto-generated\"]\n",
        "            }\n",
        "        \n",
        "        # Step 3: Execute MCP tool with extracted parameters\n",
        "        print(\"\\nüõ†Ô∏è  Step 3: Executing MCP tool with extracted parameters...\")\n",
        "        \n",
        "        # Prepare additional_fields\n",
        "        additional_fields = {}\n",
        "        if \"priority\" in issue_params:\n",
        "            additional_fields[\"priority\"] = {\"name\": issue_params[\"priority\"]}\n",
        "        if \"labels\" in issue_params:\n",
        "            additional_fields[\"labels\"] = issue_params[\"labels\"]\n",
        "        \n",
        "        # Call MCP tool\n",
        "        mcp_result = client.tool_runtime.invoke_tool(\n",
        "            tool_name=\"jira_create_issue\",\n",
        "            kwargs={\n",
        "                \"project_key\": issue_params.get(\"project_key\", \"KAN\"),\n",
        "                \"summary\": issue_params.get(\"summary\", \"Conversations API Issue\"),\n",
        "                \"issue_type\": issue_params.get(\"issue_type\", \"Task\"),\n",
        "                \"description\": issue_params.get(\"description\", prompt),\n",
        "                \"additional_fields\": additional_fields\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ MCP tool executed successfully!\")\n",
        "        print(f\"Result: {mcp_result}\")\n",
        "        \n",
        "        # Step 4: Get final confirmation from Conversations API\n",
        "        print(\"\\nü§ñ Step 4: Getting final confirmation from Conversations API...\")\n",
        "        \n",
        "        final_response = client.responses.create(\n",
        "            model=model_id,\n",
        "            input=f\"\"\"The Jira issue has been created successfully! Here are the details:\n",
        "            \n",
        "            Issue Parameters Used:\n",
        "            - Project: {issue_params.get('project_key', 'KAN')}\n",
        "            - Summary: {issue_params.get('summary', 'Conversations API Issue')}\n",
        "            - Type: {issue_params.get('issue_type', 'Task')}\n",
        "            - Description: {issue_params.get('description', prompt)}\n",
        "            - Priority: {issue_params.get('priority', 'Medium')}\n",
        "            - Labels: {issue_params.get('labels', [])}\n",
        "            \n",
        "            MCP Tool Result: {mcp_result}\n",
        "            \n",
        "            Please provide a friendly confirmation message to the user that the issue was created successfully.\"\"\",\n",
        "            previous_response_id=conversation_response.id\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ Final confirmation received!\")\n",
        "        print(f\"Final response: {final_response.output[0].content[0].text}\")\n",
        "        \n",
        "        return {\n",
        "            \"conversation_response\": conversation_response,\n",
        "            \"issue_params\": issue_params,\n",
        "            \"mcp_result\": mcp_result,\n",
        "            \"final_response\": final_response\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Simple Jira Issue Creation using Hybrid Approach\n",
        "print(\"üß™ Test 1: Create Simple Jira Issue using Hybrid Approach\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result1 = create_jira_with_conversations(\n",
        "    \"Create a Jira issue in the KAN project with summary 'Hybrid Conversations API Test' and type 'Task'\"\n",
        ")\n",
        "\n",
        "if result1:\n",
        "    print(\"üéâ Test 1 SUCCESS: Issue created using hybrid approach!\")\n",
        "    print(f\"Conversation Response ID: {result1['conversation_response'].id}\")\n",
        "    print(f\"Final Response ID: {result1['final_response'].id}\")\n",
        "else:\n",
        "    print(\"‚ùå Test 1 FAILED: Issue not created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: OOM Error Incident Creation using Hybrid Approach\n",
        "print(\"\\nüß™ Test 2: Create OOM Error Incident using Hybrid Approach\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result2 = create_jira_with_conversations(\n",
        "    \"\"\"Create a Jira incident for a pod failing due to OOM error in the KAN project:\n",
        "    - Summary: 'Pod failing due to OOM error'\n",
        "    - Issue Type: 'Incident'\n",
        "    - Description: 'Pod experiencing Out of Memory errors causing application failures'\n",
        "    - Priority: High\n",
        "    - Labels: ['oom-error', 'pod-failure', 'high-priority']\"\"\",\n",
        "    previous_response_id=result1['conversation_response'].id if result1 else None\n",
        ")\n",
        "\n",
        "if result2:\n",
        "    print(\"üéâ Test 2 SUCCESS: OOM incident created using hybrid approach!\")\n",
        "    print(f\"Conversation Response ID: {result2['conversation_response'].id}\")\n",
        "    print(f\"Final Response ID: {result2['final_response'].id}\")\n",
        "else:\n",
        "    print(\"‚ùå Test 2 FAILED: OOM incident not created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 3: Verify Issues Were Created\n",
        "print(\"\\nüß™ Test 3: Verify Issues Were Created\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "try:\n",
        "    # Use direct tool call to verify issues were created\n",
        "    search_result = client.tool_runtime.invoke_tool(\n",
        "        tool_name=\"jira_search\",\n",
        "        kwargs={\"jql\": \"project = KAN ORDER BY created DESC\"}\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Direct search completed!\")\n",
        "    \n",
        "    # Check if our test issues were created\n",
        "    search_text = str(search_result)\n",
        "    if \"Hybrid Conversations API Test\" in search_text:\n",
        "        print(\"üéâ SUCCESS: Hybrid Conversations API Test issue found!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Hybrid Conversations API Test issue not found\")\n",
        "        \n",
        "    if \"OOM error\" in search_text:\n",
        "        print(\"üéâ SUCCESS: OOM error incident found!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  OOM error incident not found\")\n",
        "        \n",
        "    print(f\"\\nRecent issues in KAN project:\")\n",
        "    print(search_result)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Search failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a **Hybrid Approach** using Conversations API + MCP Tools:\n",
        "\n",
        "### üîç **Key Discovery:**\n",
        "**Conversations API doesn't support MCP tools directly** - it only supports built-in tools like `web_search`, `file_search`, and `function`.\n",
        "\n",
        "### üîß **Hybrid Solution:**\n",
        "1. **Conversations API** - For natural conversation flow and AI reasoning\n",
        "2. **MCP Tools** - For actual Jira operations (create, search, etc.)\n",
        "3. **JSON Parsing** - Extract structured data from AI responses\n",
        "4. **Manual Execution** - Call MCP tools with extracted parameters\n",
        "\n",
        "### üöÄ **How It Works:**\n",
        "1. **Step 1**: Use Conversations API to analyze the request and generate structured parameters\n",
        "2. **Step 2**: Parse the AI's JSON response to extract Jira issue parameters\n",
        "3. **Step 3**: Execute MCP tools with the extracted parameters\n",
        "4. **Step 4**: Use Conversations API again for final confirmation and user feedback\n",
        "\n",
        "### üéØ **What We Tested:**\n",
        "1. **Simple Jira Issue Creation** - Basic task creation with hybrid approach\n",
        "2. **OOM Error Incident Creation** - Complex incident with conversation context\n",
        "3. **Issue Verification** - Direct search to confirm issues were created\n",
        "\n",
        "### üí° **Advantages:**\n",
        "- ‚úÖ **Natural conversation flow** - AI can reason about the request\n",
        "- ‚úÖ **Automatic parameter extraction** - AI generates structured data\n",
        "- ‚úÖ **Reliable tool execution** - MCP tools work perfectly\n",
        "- ‚úÖ **User-friendly responses** - AI provides confirmation messages\n",
        "- ‚úÖ **Conversation context** - Can branch from previous responses\n",
        "\n",
        "### üîÑ **API Pattern:**\n",
        "```python\n",
        "# Step 1: Get AI analysis\n",
        "conversation_response = client.responses.create(\n",
        "    model=model_id,\n",
        "    input=\"Analyze request and provide JSON parameters\",\n",
        "    previous_response_id=previous_id  # Optional for branching\n",
        ")\n",
        "\n",
        "# Step 2: Parse JSON and extract parameters\n",
        "issue_params = json.loads(extracted_json)\n",
        "\n",
        "# Step 3: Execute MCP tool\n",
        "mcp_result = client.tool_runtime.invoke_tool(\n",
        "    tool_name=\"jira_create_issue\",\n",
        "    kwargs=issue_params\n",
        ")\n",
        "\n",
        "# Step 4: Get final confirmation\n",
        "final_response = client.responses.create(\n",
        "    model=model_id,\n",
        "    input=\"Confirm success to user\",\n",
        "    previous_response_id=conversation_response.id\n",
        ")\n",
        "```\n",
        "\n",
        "**This hybrid approach gives you the best of both worlds: natural conversation flow + reliable tool execution!**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
